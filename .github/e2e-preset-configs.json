{
  "matrix": {
    "image": [
      {
        "name": "falcon-7b",
        "node-count": 1,
        "node-vm-size": "Standard_NC6s_v3",
        "node-osdisk-size": 100,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "falcon7b",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype bfloat16",
            "gpu_count": 1
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype float16 --chat-template /workspace/chat_templates/falcon-instruct.jinja",
            "gpu_count": 1
          }
        }
      },
      {
        "name": "falcon-7b-instruct",
        "node-count": 1,
        "node-vm-size": "Standard_NC6s_v3",
        "node-osdisk-size": 100,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "falcon7binst",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype bfloat16",
            "gpu_count": 1
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype bfloat16 --chat-template /workspace/chat_templates/falcon-instruct.jinja --tensor-parallel-size 2",
            "gpu_count": 2
          }
        }
      },
      {
        "name": "falcon-40b",
        "node-count": 1,
        "node-vm-size": "Standard_NC48ads_A100_v4",
        "node-osdisk-size": 400,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "falcon40b",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype bfloat16",
            "gpu_count": 2
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype bfloat16 --chat-template /workspace/chat_templates/falcon-instruct.jinja --tensor-parallel-size 2",
            "gpu_count": 2
          }
        }
      },
      {
        "name": "falcon-40b-instruct",
        "node-count": 1,
        "node-vm-size": "Standard_NC48ads_A100_v4",
        "node-osdisk-size": 400,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "falcon40bins",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype bfloat16",
            "gpu_count": 2
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype bfloat16 --chat-template /workspace/chat_templates/falcon-instruct.jinja --tensor-parallel-size 2",
            "gpu_count": 2
          }
        }
      },
      {
        "name": "mistral-7b",
        "node-count": 1,
        "node-vm-size": "Standard_NC6s_v3",
        "node-osdisk-size": 100,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "mistral7b",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype bfloat16",
            "gpu_count": 1
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype float16 --chat-template /workspace/chat_templates/mistral-instruct.jinja",
            "gpu_count": 1
          }
        }
      },
      {
        "name": "mistral-7b-instruct",
        "node-count": 1,
        "node-vm-size": "Standard_NC6s_v3",
        "node-osdisk-size": 100,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "mistral7bins",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype bfloat16",
            "gpu_count": 1
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype float16",
            "gpu_count": 1
          }
        }
      },
      {
        "name": "phi-2",
        "node-count": 1,
        "node-vm-size": "Standard_NC6s_v3",
        "node-osdisk-size": 50,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "phi2",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype bfloat16",
            "gpu_count": 1
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype float16",
            "gpu_count": 1
          }
        }
      },
      {
        "name": "phi-3-mini-4k-instruct",
        "node-count": 1,
        "node-vm-size": "Standard_NC6s_v3",
        "node-osdisk-size": 50,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "phi3mini4kin",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype auto --trust_remote_code",
            "gpu_count": 1
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype float16",
            "gpu_count": 1
          }
        }
      },
      {
        "name": "phi-3-mini-128k-instruct",
        "node-count": 1,
        "node-vm-size": "Standard_NC6s_v3",
        "node-osdisk-size": 50,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "phi3mini128k",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype auto --trust_remote_code",
            "gpu_count": 1
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype float16",
            "gpu_count": 1
          }
        }
      },
      {
        "name": "phi-3-medium-4k-instruct",
        "node-count": 1,
        "node-vm-size": "Standard_NC12s_v3",
        "node-osdisk-size": 100,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "phi3medium4k",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype auto --trust_remote_code",
            "gpu_count": 1
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype float16 --tensor-parallel-size 2",
            "gpu_count": 2
          }
        }
      },
      {
        "name": "phi-3-medium-128k-instruct",
        "node-count": 1,
        "node-vm-size": "Standard_NC12s_v3",
        "node-osdisk-size": 100,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "phi3medium12",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype auto --trust_remote_code",
            "gpu_count": 1
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --dtype float16 --max-model-len 1024 --tensor-parallel-size 2",
            "gpu_count": 2
          }
        }
      },
      {
        "name": "qwen2.5-coder-7b-instruct",
        "workload": "qwen2-5-coder-7b-instruct",
        "node-count": 1,
        "node-vm-size": "Standard_NC12s_v3",
        "node-osdisk-size": 100,
        "OSS": true,
        "loads_adapter": false,
        "node_pool": "qwen25coder7",
        "runtimes": {
          "hf": {
            "command": "accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all /workspace/tfs/inference_api.py --pipeline text-generation --torch_dtype auto --trust_remote_code",
            "gpu_count": 1
          },
          "vllm": {
            "command": "python3 /workspace/vllm/inference_api.py --kaito-config-file /mnt/config/inference_config.yaml --tensor-parallel-size 2",
            "gpu_count": 2
          }
        }
      },
      {
        "name": "llama-2-7b",
        "node-count": 1,
        "node-vm-size": "Standard_NC12s_v3",
        "node-osdisk-size": 100,
        "OSS": false,
        "loads_adapter": false,
        "kind": "StatefulSet",
        "node_pool": "llama27b",
        "runtimes": {
          "hf": {
            "command": "cd /workspace/llama/llama-2 && torchrun inference_api.py",
            "gpu_count": 1
          }
        }
      },
      {
        "name": "llama-2-7b-chat",
        "node-count": 1,
        "node-vm-size": "Standard_NC12s_v3",
        "node-osdisk-size": 100,
        "OSS": false,
        "loads_adapter": false
      },
      {
        "name": "llama-2-13b",
        "node-count": 2,
        "node-vm-size": "Standard_NC12s_v3",
        "node-osdisk-size": 150,
        "OSS": false,
        "loads_adapter": false,
        "kind": "StatefulSet",
        "node_pool": "llama213b",
        "runtimes": {
          "hf": {
            "command": "echo \"MASTER_ADDR: $MASTER_ADDR\"\nNODE_RANK=$(echo $HOSTNAME | grep -o '[^-]*$')\ncd /workspace/llama/llama-2 && torchrun --nnodes 2 --nproc_per_node 1 --node_rank $NODE_RANK --master-addr $MASTER_ADDR --master-port 29500 inference_api.py",
            "gpu_count": 1
          }
        }
      },
      {
        "name": "llama-2-13b-chat",
        "node-count": 2,
        "node-vm-size": "Standard_NC12s_v3",
        "node-osdisk-size": 150,
        "OSS": false,
        "loads_adapter": false
      },
      {
        "name": "tuning",
        "node-count": 1,
        "node-vm-size": "Standard_NC6s_v3",
        "node-osdisk-size": 100,
        "OSS": true,
        "loads_adapter": false
      }
    ]
  }
}

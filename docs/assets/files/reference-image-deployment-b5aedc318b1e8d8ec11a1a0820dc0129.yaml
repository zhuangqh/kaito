apiVersion: kaito.sh/v1beta1
kind: Workspace
metadata:
  name: workspace-custom-llm
resource:
  instanceType: "Standard_NC24ads_A100_v4" # Replace with the required VM SKU based on model requirements
  labelSelector:
    matchLabels:
      apps: custom-llm
#  preferredNodes:
#    - <PREFERRED_NODE_HERE>
inference:
  template:
    spec:
      containers:
        - name: custom-llm-container
          image: ghcr.io/kaito-project/kaito/llm-reference-preset:latest # Kaito Reference Image
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 5000
              scheme: HTTP
            initialDelaySeconds: 600
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 5000
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              nvidia.com/gpu: 1  # Request 1 GPU; adjust as needed
            limits:
              nvidia.com/gpu: 1  # Optional: Limit to 1 GPU
          command:
            - "accelerate"
          args:
            - "launch"
            - "--num_processes"
            - "1"
            - "--num_machines"
            - "1"
            - "--gpu_ids"
            - "all"
            - "inference_api.py"
            - "--pipeline"
            - "text-generation"
            - "--trust_remote_code"
            - "--allow_remote_files"
            - "--pretrained_model_name_or_path"
            - "<MODEL_ID>"  # Replace <MODEL_ID> with the specific HuggingFace model identifier
            - "--torch_dtype"
            - "float16"  # Set to "float16" for compatibility with V100 GPUs; use "bfloat16" for A100, H100 or newer GPUs
          # env:
          #   HF_TOKEN is required only for private or gated Hugging Face models
          #   Uncomment and configure this block if needed
          #   - name: HF_TOKEN
          #     valueFrom:
          #       secretKeyRef:
          #         name: hf-token-secret     # Replace with your Kubernetes Secret name
          #         key: HF_TOKEN             # Replace with the specific key holding the token
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory

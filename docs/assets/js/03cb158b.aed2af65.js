"use strict";(self.webpackChunkkaito_website=self.webpackChunkkaito_website||[]).push([[8403],{28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>l});var i=t(96540);const a={},s=i.createContext(a);function r(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:n},e.children)}},95741:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"keda-autoscaler-inference","title":"KEDA Auto-Scaler for inference workloads","description":"- Feature status: Alpha","source":"@site/docs/keda-autoscaler-inference.md","sourceDirName":".","slug":"/keda-autoscaler-inference","permalink":"/kaito/docs/next/keda-autoscaler-inference","draft":false,"unlisted":false,"editUrl":"https://github.com/kaito-project/kaito/tree/main/website/docs/keda-autoscaler-inference.md","tags":[],"version":"current","frontMatter":{"title":"KEDA Auto-Scaler for inference workloads"},"sidebar":"sidebar","previous":{"title":"Multi-Node Inference","permalink":"/kaito/docs/next/multi-node-inference"},"next":{"title":"Fine Tuning","permalink":"/kaito/docs/next/tuning"}}');var a=t(74848),s=t(28453);const r={title:"KEDA Auto-Scaler for inference workloads"},l=void 0,c={},o=[{value:"Overview",id:"overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Enable this feature",id:"enable-this-feature",level:2},{value:"Quickstart",id:"quickstart",level:2},{value:"Create a Kaito InferenceSet for running inference workloads",id:"create-a-kaito-inferenceset-for-running-inference-workloads",level:3}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Feature status: Alpha"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(n.p,{children:"This document outlines the steps to enable intelligent autoscaling for KAITO inference workloads by utilizing the following components and features:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://github.com/kedacore/keda",children:"KEDA"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Kubernetes-based Event Driven Autoscaling component"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://github.com/kaito-project/keda-kaito-scaler",children:"keda-kaito-scaler"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"A dedicated KEDA external scaler, eliminating the need for external dependencies such as Prometheus."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["KAITO ",(0,a.jsx)(n.code,{children:"InferenceSet"})," CRD and Controller","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["This new CRD and Controller were built on top of the KAITO workspace for intelligent autoscaling, introduced as an alpha feature in KAITO version ",(0,a.jsx)(n.code,{children:"v0.8.0"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"install KEDA"}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["The following example demonstrates how to install KEDA using Helm chart. For instructions on installing KEDA through other methods, please refer to the guide ",(0,a.jsx)(n.a,{href:"https://github.com/kedacore/keda#deploying-keda",children:"here"}),"."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"helm repo add kedacore https://kedacore.github.io/charts\nhelm install keda kedacore/keda --namespace keda --create-namespace\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"install keda-kaito-scaler"}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"helm repo add keda-kaito-scaler https://kaito-project.github.io/keda-kaito-scaler/charts/kaito-project\nhelm upgrade --install keda-kaito-scaler -n kaito-workspace keda-kaito-scaler/keda-kaito-scaler --create-namespace\n"})}),"\n",(0,a.jsx)(n.h2,{id:"enable-this-feature",children:"Enable this feature"}),"\n",(0,a.jsx)(n.p,{children:"This feature is available starting from KAITO v0.8.0, and the InferenceSet Controller must be enabled during the KAITO installation."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'export CLUSTER_NAME=kaito\n\nhelm repo add kaito https://kaito-project.github.io/kaito/charts/kaito\nhelm repo update\nhelm upgrade --install kaito-workspace kaito/workspace \\\n  --namespace kaito-workspace \\\n  --create-namespace \\\n  --set clusterName="$CLUSTER_NAME" \\\n  --set featureGates.enableInferenceSetController=true \\\n  --wait\n'})}),"\n",(0,a.jsx)(n.h2,{id:"quickstart",children:"Quickstart"}),"\n",(0,a.jsx)(n.h3,{id:"create-a-kaito-inferenceset-for-running-inference-workloads",children:"Create a Kaito InferenceSet for running inference workloads"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["The following example creates an InferenceSet for the phi-4-mini model, using annotations with the prefix ",(0,a.jsx)(n.code,{children:"scaledobject.kaito.sh/"})," to supply parameter inputs for the KEDA Kaito Scaler:","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"scaledobject.kaito.sh/auto-provision"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["required, specifies whether KEDA Kaito Scaler will automatically provision a ScaledObject based on the ",(0,a.jsx)(n.code,{children:"InferenceSet"})," object"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"scaledobject.kaito.sh/metricName"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["optional, specifies the metric name collected from the vLLM pod, which is used for monitoring and triggering the scaling operation, default is ",(0,a.jsx)(n.code,{children:"vllm:num_requests_waiting"})]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"scaledobject.kaito.sh/threshold"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"required, specifies the threshold for the monitored metric that triggers the scaling operation"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'cat <<EOF | kubectl apply -f -\napiVersion: kaito.sh/v1alpha1\nkind: InferenceSet\nmetadata:\n  annotations:\n    scaledobject.kaito.sh/auto-provision: "true"\n    scaledobject.kaito.sh/metricName: "vllm:num_requests_waiting"\n    scaledobject.kaito.sh/threshold: "10"\n  name: phi-4-mini\n  namespace: default\nspec:\n  labelSelector:\n    matchLabels:\n      apps: phi-4-mini\n  replicas: 1\n  nodeCountLimit: 5\n  template:\n    inference:\n      preset:\n        accessMode: public\n        name: phi-4-mini-instruct\n    resource:\n      instanceType: Standard_NC24ads_A100_v4\nEOF\n'})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["In just a few seconds, the KEDA Kaito Scaler will automatically create the ",(0,a.jsx)(n.code,{children:"scaledobject"})," and ",(0,a.jsx)(n.code,{children:"hpa"})," objects. After a few minutes, once the inference pod is running, the KEDA Kaito Scaler will begin scraping metric values from the inference pod, and the status of the ",(0,a.jsx)(n.code,{children:"scaledobject"})," and ",(0,a.jsx)(n.code,{children:"hpa"})," objects will be marked as ready."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# kubectl get scaledobject\nNAME           SCALETARGETKIND                  SCALETARGETNAME   MIN   MAX   READY   ACTIVE    FALLBACK   PAUSED   TRIGGERS   AUTHENTICATIONS           AGE\nphi-4-mini     kaito.sh/v1alpha1.InferenceSet   phi-4-mini        1     5     True    True     False      False    external   keda-kaito-scaler-creds   10m\n\n# kubectl get hpa\nNAME                    REFERENCE                   TARGETS      MINPODS   MAXPODS   REPLICAS   AGE\nkeda-hpa-phi-4-mini     InferenceSet/phi-4-mini     0/10 (avg)   1         5         1          11m\n"})}),"\n",(0,a.jsxs)(n.p,{children:["That's it! Your KAITO workloads will now automatically scale based on the number of waiting inference requests(",(0,a.jsx)(n.code,{children:"vllm:num_requests_waiting"}),")."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);
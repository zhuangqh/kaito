"use strict";(self.webpackChunkkaito_website=self.webpackChunkkaito_website||[]).push([[260],{1552:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>i,contentTitle:()=>t,default:()=>u,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var o=a(4848),s=a(8453);const r={title:"Bring Your Own GPU Nodes"},t=void 0,l={id:"kaito-on-byo-gpu-nodes",title:"Bring Your Own GPU Nodes",description:"This guide walks you through deploying KAITO on a Kubernetes cluster with self-provisioned GPU nodes.",source:"@site/docs/kaito-on-byo-gpu-nodes.md",sourceDirName:".",slug:"/kaito-on-byo-gpu-nodes",permalink:"/kaito/docs/kaito-on-byo-gpu-nodes",draft:!1,unlisted:!1,editUrl:"https://github.com/kaito-project/kaito/tree/main/website/docs/kaito-on-byo-gpu-nodes.md",tags:[],version:"current",frontMatter:{title:"Bring Your Own GPU Nodes"},sidebar:"sidebar",previous:{title:"OOM Prevention",permalink:"/kaito/docs/kaito-oom-prevention"},next:{title:"Contributing",permalink:"/kaito/docs/contributing"}},i={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Tools",id:"tools",level:3},{value:"Set up a Kubernetes cluster with GPU nodes",id:"set-up-a-kubernetes-cluster-with-gpu-nodes",level:2},{value:"Environment variables",id:"environment-variables",level:3},{value:"Create a resource group",id:"create-a-resource-group",level:3},{value:"Create an Azure Kubernetes Service (AKS) cluster",id:"create-an-azure-kubernetes-service-aks-cluster",level:3},{value:"Add GPU nodes",id:"add-gpu-nodes",level:3},{value:"Download kubeconfig",id:"download-kubeconfig",level:3},{value:"Prepare the Kubernetes cluster for GPU workloads",id:"prepare-the-kubernetes-cluster-for-gpu-workloads",level:2},{value:"Install the NVIDIA GPU operator",id:"install-the-nvidia-gpu-operator",level:3},{value:"Label the GPU nodes",id:"label-the-gpu-nodes",level:3},{value:"Install KAITO on the Kubernetes cluster",id:"install-kaito-on-the-kubernetes-cluster",level:2},{value:"Deploying a model",id:"deploying-a-model",level:2},{value:"Deploy a workspace with a GPU model",id:"deploy-a-workspace-with-a-gpu-model",level:3},{value:"Use the workspace",id:"use-the-workspace",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:"This guide walks you through deploying KAITO on a Kubernetes cluster with self-provisioned GPU nodes."}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(n.p,{children:"If you are following the demo as is then you would need access to an Azure account."}),"\n",(0,o.jsx)(n.h3,{id:"tools",children:"Tools"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/cli/azure/install-azure-cli",children:"Azure CLI"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://kubernetes.io/docs/tasks/tools/#kubectl",children:"kubectl"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://helm.sh/docs/intro/install/",children:"Helm"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://jqlang.github.io/jq/download/",children:"jq"})}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"set-up-a-kubernetes-cluster-with-gpu-nodes",children:"Set up a Kubernetes cluster with GPU nodes"}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsx)(n.p,{children:"If you already have a Kubernetes cluster, you can skip this section."})}),"\n",(0,o.jsx)(n.p,{children:"For the sake of this guide, we will create an Azure Kubernetes Service (AKS) cluster."}),"\n",(0,o.jsx)(n.h3,{id:"environment-variables",children:"Environment variables"}),"\n",(0,o.jsx)(n.p,{children:"Make necessary changes to the following environment variables and copy paste them into your terminal:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'export LOCATION="southcentralus"\nexport RESOURCE_GROUP="kaito-rg"\nexport AKS_RG="${RESOURCE_GROUP}-aks"\nexport CLUSTER_NAME="kaito"\nexport AKS_WORKER_USER_NAME="azuser"\nexport SSH_KEY=~/.ssh/id_rsa.pub\nexport GPU_NODE_SIZE="Standard_NC24ads_A100_v4"\nexport GPU_NODE_COUNT=1\nexport GPU_NODE_POOL_NAME="gpunodes"\n'})}),"\n",(0,o.jsx)(n.h3,{id:"create-a-resource-group",children:"Create a resource group"}),"\n",(0,o.jsx)(n.p,{children:"Run the following command to create a resource group:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'az group create \\\n    --name "${RESOURCE_GROUP}" \\\n    --location "${LOCATION}"\n'})}),"\n",(0,o.jsx)(n.h3,{id:"create-an-azure-kubernetes-service-aks-cluster",children:"Create an Azure Kubernetes Service (AKS) cluster"}),"\n",(0,o.jsx)(n.p,{children:"Run the following command to create an AKS cluster:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'az aks create \\\n    --resource-group "${RESOURCE_GROUP}" \\\n    --node-resource-group "${AKS_RG}" \\\n    --name "${CLUSTER_NAME}" \\\n    --enable-oidc-issuer \\\n    --enable-workload-identity \\\n    --enable-managed-identity \\\n    --node-count 1 \\\n    --location "${LOCATION}" \\\n    --ssh-key-value "${SSH_KEY}" \\\n    --admin-username "${AKS_WORKER_USER_NAME}" \\\n    --os-sku Ubuntu\n'})}),"\n",(0,o.jsx)(n.h3,{id:"add-gpu-nodes",children:"Add GPU nodes"}),"\n",(0,o.jsxs)(n.p,{children:["Run the following commands to add or update the ",(0,o.jsx)(n.code,{children:"aks-preview"})," extension:"]}),"\n",(0,o.jsx)(n.admonition,{type:"warning",children:(0,o.jsxs)(n.p,{children:["This is needed to enable the ",(0,o.jsx)(n.code,{children:"--skip-gpu-driver-install"})," flag, you can read more about it ",(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/azure/aks/gpu-cluster?tabs=add-ubuntu-gpu-node-pool#skip-gpu-driver-installation-preview",children:"here"}),"."]})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"az extension add --name aks-preview\naz extension update --name aks-preview\n"})}),"\n",(0,o.jsx)(n.p,{children:"Run the following command to add GPU node to the AKS cluster:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'az aks nodepool add \\\n    --name "${GPU_NODE_POOL_NAME}" \\\n    --resource-group "${RESOURCE_GROUP}" \\\n    --cluster-name "${CLUSTER_NAME}" \\\n    --node-count "${GPU_NODE_COUNT}" \\\n    --node-vm-size "${GPU_NODE_SIZE}" \\\n    --skip-gpu-driver-install\n'})}),"\n",(0,o.jsx)(n.h3,{id:"download-kubeconfig",children:"Download kubeconfig"}),"\n",(0,o.jsx)(n.p,{children:"Run the following command to download the kubeconfig file:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'az aks get-credentials \\\n    --resource-group "${RESOURCE_GROUP}" \\\n    --name "${CLUSTER_NAME}"\n'})}),"\n",(0,o.jsx)(n.h2,{id:"prepare-the-kubernetes-cluster-for-gpu-workloads",children:"Prepare the Kubernetes cluster for GPU workloads"}),"\n",(0,o.jsx)(n.h3,{id:"install-the-nvidia-gpu-operator",children:"Install the NVIDIA GPU operator"}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsx)(n.p,{children:"If you have already set up your Kubernetes cluster with Nvidia's GPU operator, you can skip the GPU operator installation."})}),"\n",(0,o.jsx)(n.p,{children:"Run the following commands to create a namespace for the GPU operator:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"kubectl create ns gpu-operator\nkubectl label --overwrite ns gpu-operator pod-security.kubernetes.io/enforce=privileged\n"})}),"\n",(0,o.jsx)(n.p,{children:"Run the following commands to install the GPU operator:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"helm repo add nvidia https://helm.ngc.nvidia.com/nvidia\nhelm repo update\n\nhelm install \\\n    --wait \\\n    --generate-name \\\n    -n gpu-operator \\\n    --create-namespace \\\n    nvidia/gpu-operator\n"})}),"\n",(0,o.jsx)(n.p,{children:"Ensure that the GPU operator is installed by running the following command:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"kubectl -n gpu-operator wait pod \\\n    --for=condition=Ready \\\n    -l app.kubernetes.io/component=gpu-operator \\\n    --timeout=300s\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Finally ensure that the ",(0,o.jsx)(n.code,{children:"nvidia"})," runtime class is created by running the following command:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"kubectl get runtimeclass nvidia\n"})}),"\n",(0,o.jsx)(n.p,{children:"A typical output would look like this:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"$ kubectl get runtimeclass nvidia\nNAME     HANDLER   AGE\nnvidia   nvidia    16m\n"})}),"\n",(0,o.jsx)(n.h3,{id:"label-the-gpu-nodes",children:"Label the GPU nodes"}),"\n",(0,o.jsxs)(n.p,{children:["We need to label the GPU nodes ",(0,o.jsx)(n.code,{children:"apps=gpu"}),", so that the KAITO workspace controller can schedule the inference workloads on these nodes. If you are following along the guide, you can run the following command to label the GPU nodes:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'kubectl get nodes \\\n    -l agentpool="${GPU_NODE_POOL_NAME}" \\\n    -o name | \\\n    xargs -I {} \\\n    kubectl label --overwrite {} apps=gpu\n'})}),"\n",(0,o.jsx)(n.admonition,{type:"tip",children:(0,o.jsxs)(n.p,{children:["If you have used a different set up to create the GPU nodes, you can label the nodes manually by running the following command: ",(0,o.jsx)(n.code,{children:"kubectl label node <node-name> apps=gpu"}),"."]})}),"\n",(0,o.jsx)(n.h2,{id:"install-kaito-on-the-kubernetes-cluster",children:"Install KAITO on the Kubernetes cluster"}),"\n",(0,o.jsx)(n.p,{children:"Run the following command to install KAITO:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"helm install workspace \\\n    ./charts/kaito/workspace \\\n    --namespace kaito-workspace \\\n    --create-namespace\n"})}),"\n",(0,o.jsx)(n.p,{children:"Ensure that kaito is installed by running the following command:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"kubectl -n kaito-workspace wait pod \\\n    --for=condition=Ready \\\n    -l app.kubernetes.io/instance=workspace \\\n    --timeout=300s\n"})}),"\n",(0,o.jsx)(n.h2,{id:"deploying-a-model",children:"Deploying a model"}),"\n",(0,o.jsx)(n.h3,{id:"deploy-a-workspace-with-a-gpu-model",children:"Deploy a workspace with a GPU model"}),"\n",(0,o.jsx)(n.p,{children:"To deploy a workspace with a GPU model, run the following command:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:'cat <<EOF | kubectl apply -f -\napiVersion: kaito.sh/v1beta1\nkind: Workspace\nmetadata:\n  name: workspace-falcon-7b\nresource:\n  instanceType: "${GPU_NODE_SIZE}"\n  labelSelector:\n    matchLabels:\n      apps: gpu\ninference:\n  preset:\n    name: "falcon-7b"\nEOF\n'})}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["In the above configuration you can see we have use a node labelSelector value as ",(0,o.jsx)(n.code,{children:"apps: gpu"}),", this is the same label we have applied when we added the GPU node pool earlier."]})}),"\n",(0,o.jsx)(n.p,{children:"Ensure that the workspace is ready by running the following command:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"kubectl get workspace workspace-falcon-7b\n"})}),"\n",(0,o.jsx)(n.p,{children:"A typical output would look like this:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"$ kubectl get workspace workspace-falcon-7b\nNAME                  INSTANCE                   RESOURCEREADY   INFERENCEREADY   JOBSTARTED   WORKSPACESUCCEEDED   AGE\nworkspace-falcon-7b   Standard_NC24ads_A100_v4   True            True                          True                 16m\n"})}),"\n",(0,o.jsx)(n.h3,{id:"use-the-workspace",children:"Use the workspace"}),"\n",(0,o.jsx)(n.p,{children:"Run the following command to find the cluster IP to send the request to:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'export CLUSTERIP=$(kubectl get \\\n    svc workspace-falcon-7b \\\n    -o jsonpath="{.spec.clusterIPs[0]}")\n'})}),"\n",(0,o.jsx)(n.p,{children:"Let's send a request to the workspace to get an inference response. Modify the prompt as you see fit:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'export QUESTION="What\'s are LLMs?"\n'})}),"\n",(0,o.jsx)(n.p,{children:"Run the following command to send the request:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'kubectl run -it --rm \\\n    --restart=Never \\\n    curl --image=curlimages/curl \\\n    -- curl -X POST http://$CLUSTERIP/chat \\\n    -H "accept: application/json" \\\n    -H "Content-Type: application/json" \\\n    -d "{\\"prompt\\":\\"${QUESTION}\\"}" | jq\n'})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>t,x:()=>l});var o=a(6540);const s={},r=o.createContext(s);function t(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);
"use strict";(self.webpackChunkkaito_website=self.webpackChunkkaito_website||[]).push([[108],{2920:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>o,default:()=>u,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var i=t(4848),s=t(8453);const a={title:"Retrieval-Augmented Generation (RAG)"},o=void 0,l={id:"rag",title:"Retrieval-Augmented Generation (RAG)",description:"This document presents how to use the KAITO ragengine Custom Resource Definition (CRD) for retrieval-augumented generatoin workflow. By creating a RAGEngine resource, you can quickly stand up a service that indexes documents and queries them in conjunction with an existing LLM inference endpoint\u2014no need to custom-build pipelines. This enables your large language model to answer questions based on your own private content.",source:"@site/docs/rag.md",sourceDirName:".",slug:"/rag",permalink:"/kaito/docs/rag",draft:!1,unlisted:!1,editUrl:"https://github.com/kaito-project/kaito/tree/main/website/docs/rag.md",tags:[],version:"current",frontMatter:{title:"Retrieval-Augmented Generation (RAG)"},sidebar:"sidebar",previous:{title:"Fine Tuning",permalink:"/kaito/docs/tuning"},next:{title:"Custom Model Integration",permalink:"/kaito/docs/custom-model"}},r={},c=[{value:"Installation",id:"installation",level:2},{value:"Verify installation",id:"verify-installation",level:2},{value:"Clean up",id:"clean-up",level:2},{value:"Usage",id:"usage",level:2},{value:"Prerequisite",id:"prerequisite",level:3},{value:"Define the RAGEngine",id:"define-the-ragengine",level:3},{value:"Splitting Documents with CodeSplitter",id:"splitting-documents-with-codesplitter",level:3},{value:"Apply the Manifest",id:"apply-the-manifest",level:3}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["This document presents how to use the KAITO ",(0,i.jsx)(n.code,{children:"ragengine"})," Custom Resource Definition (CRD) for retrieval-augumented generatoin workflow. By creating a RAGEngine resource, you can quickly stand up a service that indexes documents and queries them in conjunction with an existing LLM inference endpoint\u2014no need to custom-build pipelines. This enables your large language model to answer questions based on your own private content."]}),"\n",(0,i.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["Be sure you've cloned this repo and followed ",(0,i.jsx)(n.a,{href:"/kaito/docs/installation",children:"kaito workspace installation"})]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"helm install ragengine ./charts/kaito/ragengine --namespace kaito-ragengine --create-namespace\n"})}),"\n",(0,i.jsx)(n.h2,{id:"verify-installation",children:"Verify installation"}),"\n",(0,i.jsx)(n.p,{children:"You can run the following commands to verify the installation of the controllers were successful."}),"\n",(0,i.jsx)(n.p,{children:"Check status of the Helm chart installations."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"helm list -n kaito-ragengine\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Check status of the ",(0,i.jsx)(n.code,{children:"ragengine"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"kubectl describe deploy ragengine -n kaito-ragengine\n"})}),"\n",(0,i.jsx)(n.h2,{id:"clean-up",children:"Clean up"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"helm uninstall kaito-ragengine\n"})}),"\n",(0,i.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,i.jsx)(n.h3,{id:"prerequisite",children:"Prerequisite"}),"\n",(0,i.jsx)(n.p,{children:"Before creating a RAGEngine, ensure you have an accessible model inference endpoint. This endpoint can be:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"A model deployed through KAITO Workspace CRD (e.g., a local Hugging Face model, a vLLM instance, etc.)."}),"\n",(0,i.jsx)(n.li,{children:"An external API (e.g., Huggingface service or other REST-based LLM providers)."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"define-the-ragengine",children:"Define the RAGEngine"}),"\n",(0,i.jsx)(n.p,{children:"Create a YAML manifest defining your RAGEngine. Key fields under spec include:"}),"\n",(0,i.jsx)(n.p,{children:"Embedding: how to generate vector embeddings for your documents. You may choose remote or local (one must be left unset if you pick the other):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'embedding:\n    local:\n      modelID: "BAAI/bge-small-en-v1.5"\n'})}),"\n",(0,i.jsx)(n.p,{children:"InferenceService: points to the LLM endpoint that RAGEngine will call for final text generation."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'inferenceService:\n  url: "<inference-url>/v1/completions"\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Users also need to specify the GPU SKU used for inference in the ",(0,i.jsx)(n.code,{children:"compute"})," spec. For example,"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'apiVersion: kaito.sh/v1alpha1\nkind: RAGEngine\nmetadata:\n  name: ragengine-start\nspec:\n  compute:\n    instanceType: "Standard_NC6s_v3"\n    labelSelector:\n      matchLabels:\n        apps: ragengine-example\n  embedding:\n    local:\n      modelID: "BAAI/bge-small-en-v1.5"\n  inferenceService:\n    url: "<inference-url>/v1/completions"\n'})}),"\n",(0,i.jsx)(n.h3,{id:"splitting-documents-with-codesplitter",children:"Splitting Documents with CodeSplitter"}),"\n",(0,i.jsxs)(n.p,{children:["By default, RAGEngine splits documents into sentences. However, you can instruct the engine to split documents using the ",(0,i.jsx)(n.code,{children:"CodeSplitter"})," (for code-aware chunking) by providing metadata in your API request."]}),"\n",(0,i.jsxs)(n.p,{children:["To use the ",(0,i.jsx)(n.code,{children:"CodeSplitter"}),", set the ",(0,i.jsx)(n.code,{children:"split_type"})," to ",(0,i.jsx)(n.code,{children:'"code"'})," and specify the programming language in the ",(0,i.jsx)(n.code,{children:"language"})," field of the document metadata. For example, when calling the RAGEngine API to index documents:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "documents": [\n    {\n      "text": "def foo():\\n    return 42\\n\\n# Another function\\ndef bar():\\n    pass",\n      "metadata": {\n        "split_type": "code",\n        "language": "python"\n      }\n    }\n  ]\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:["This instructs the RAGEngine to use code-aware splitting for the provided document. If ",(0,i.jsx)(n.code,{children:"split_type"})," is not set or set to any other value, sentence splitting will be used by default."]}),"\n",(0,i.jsx)(n.h3,{id:"apply-the-manifest",children:"Apply the Manifest"}),"\n",(0,i.jsx)(n.p,{children:"After you create your YAML configuration, run:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:"kubectl apply -f examples/RAG/kaito_ragengine_phi_3.yaml\n"})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>l});var i=t(6540);const s={},a=i.createContext(s);function o(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);
"use strict";(self.webpackChunkkaito_website=self.webpackChunkkaito_website||[]).push([[593],{8453:(e,s,t)=>{t.d(s,{R:()=>o,x:()=>d});var r=t(6540);const i={},n=r.createContext(i);function o(e){const s=r.useContext(n);return r.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function d(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),r.createElement(n.Provider,{value:s},e.children)}},8881:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>n,metadata:()=>d,toc:()=>a});var r=t(4848),i=t(8453);const n={title:"Proposal for Mistral model support",authors:["Ishaan Sehgal"],reviewers:["KAITO contributor"],"creation-date":new Date("2024-02-06T00:00:00.000Z"),"last-updated":new Date("2024-02-06T00:00:00.000Z"),status:"provisional"},o="Title",d={id:"proposals/phi-2",title:"Proposal for Mistral model support",description:"Add phi-2 to KAITO supported model list.",source:"@site/docs/proposals/20240206-phi-2.md",sourceDirName:"proposals",slug:"/proposals/phi-2",permalink:"/kaito/docs/proposals/phi-2",draft:!1,unlisted:!1,editUrl:"https://github.com/kaito-project/kaito/tree/main/website/docs/proposals/20240206-phi-2.md",tags:[],version:"current",sidebarPosition:20240206,frontMatter:{title:"Proposal for Mistral model support",authors:["Ishaan Sehgal"],reviewers:["KAITO contributor"],"creation-date":"2024-02-06T00:00:00.000Z","last-updated":"2024-02-06T00:00:00.000Z",status:"provisional"}},l={},a=[{value:"Glossary",id:"glossary",level:2},{value:"Summary",id:"summary",level:2},{value:"Requirements",id:"requirements",level:2},{value:"Runtimes",id:"runtimes",level:2}];function c(e){const s={a:"a",code:"code",h1:"h1",h2:"h2",input:"input",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(s.h1,{id:"title",children:"Title"}),"\n",(0,r.jsx)(s.p,{children:"Add phi-2 to KAITO supported model list."}),"\n",(0,r.jsx)(s.h2,{id:"glossary",children:"Glossary"}),"\n",(0,r.jsx)(s.p,{children:"N/A"}),"\n",(0,r.jsx)(s.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Model description"}),": Launched during Microsoft Ignite last November, Phi-2 model is intended for QA, chat, and code purposes. With only 2.7 billion parameters, Phi-2 impressively surpasses the performance of Mistral and Llama-2 models at 7B and 13B on various aggregated benchmarks. Most notably it achieves better performance compare to the 25x larger llama-2-70B model on particular reasoning tasks like coding and math."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Model usage statistics"}),": In the past month, phi-2 has garnered 535,163 downloads on Hugging Face, reflecting its widespread popularity."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Model license"}),": phi-2 is distributed under the MIT license, ensuring broad usability and modification rights."]}),"\n"]}),"\n",(0,r.jsx)(s.h2,{id:"requirements",children:"Requirements"}),"\n",(0,r.jsx)(s.p,{children:"The following table describes the basic model characteristics and the resource requirements of running it."}),"\n",(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Field"}),(0,r.jsx)(s.th,{children:"Notes"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Family name"}),(0,r.jsx)(s.td,{children:"phi-2"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Type"}),(0,r.jsx)(s.td,{children:(0,r.jsx)(s.code,{children:"text generation"})})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Download site"}),(0,r.jsx)(s.td,{children:(0,r.jsx)(s.a,{href:"https://huggingface.co/microsoft/phi-2",children:"https://huggingface.co/microsoft/phi-2"})})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Version"}),(0,r.jsx)(s.td,{children:"b10c3eba545ad279e7208ee3a5d644566f001670"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Storage size"}),(0,r.jsx)(s.td,{children:"30GB"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"GPU count"}),(0,r.jsx)(s.td,{children:"1"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Total GPU memory"}),(0,r.jsx)(s.td,{children:"12GB"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Per GPU memory"}),(0,r.jsx)(s.td,{children:(0,r.jsx)(s.code,{children:"N/A"})})]})]})]}),"\n",(0,r.jsx)(s.h2,{id:"runtimes",children:"Runtimes"}),"\n",(0,r.jsx)(s.p,{children:"This section describes how to configure the runtime framework to support the inference calls."}),"\n",(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Options"}),(0,r.jsx)(s.th,{children:"Notes"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Runtime"}),(0,r.jsx)(s.td,{children:"Huggingface Transformer"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Distributed Inference"}),(0,r.jsx)(s.td,{children:"False"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Custom configurations"}),(0,r.jsx)(s.td,{children:"Precision: FP16. Can run on one machine with total of 12GB of GPU Memory."})]})]})]}),"\n",(0,r.jsx)(s.h1,{id:"history",children:"History"}),"\n",(0,r.jsxs)(s.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(s.li,{className:"task-list-item",children:[(0,r.jsx)(s.input,{type:"checkbox",checked:!0,disabled:!0})," ","02/06/2024: Open proposal PR."]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,r.jsx)(s,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);
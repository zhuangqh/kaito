"use strict";(self.webpackChunkkaito_website=self.webpackChunkkaito_website||[]).push([[4158],{8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>s});var t=i(6540);const a={},r=t.createContext(a);function o(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(r.Provider,{value:n},e.children)}},8980:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>r,metadata:()=>s,toc:()=>l});var t=i(4848),a=i(8453);const r={title:"Inference-Aware Routing Layer",authors:["@chewong"],reviewers:["@Fei-Guo","@zhuangqh"],"creation-date":new Date("2025-07-15T00:00:00.000Z"),"last-updated":new Date("2025-07-15T00:00:00.000Z"),status:"provisional","see-also":null},o=void 0,s={id:"proposals/inference-aware-routing-layer",title:"Inference-Aware Routing Layer",description:"Goals",source:"@site/versioned_docs/version-v0.5.1/proposals/20250715-inference-aware-routing-layer.md",sourceDirName:"proposals",slug:"/proposals/inference-aware-routing-layer",permalink:"/kaito/docs/proposals/inference-aware-routing-layer",draft:!1,unlisted:!1,editUrl:"https://github.com/kaito-project/kaito/tree/main/website/versioned_docs/version-v0.5.1/proposals/20250715-inference-aware-routing-layer.md",tags:[],version:"v0.5.1",sidebarPosition:20250715,frontMatter:{title:"Inference-Aware Routing Layer",authors:["@chewong"],reviewers:["@Fei-Guo","@zhuangqh"],"creation-date":"2025-07-15T00:00:00.000Z","last-updated":"2025-07-15T00:00:00.000Z",status:"provisional","see-also":null}},c={},l=[{value:"Goals",id:"goals",level:2},{value:"Non-Goals",id:"non-goals",level:2},{value:"Gateway API Inference Extension Components",id:"gateway-api-inference-extension-components",level:2},{value:"Integration Points",id:"integration-points",level:2},{value:"CRDs Installation",id:"crds-installation",level:3},{value:"Gateway",id:"gateway",level:3},{value:"<code>InferencePool</code>",id:"inferencepool",level:3},{value:"<code>InferenceModel</code>",id:"inferencemodel",level:3},{value:"Body-Based Routing (BBR)",id:"body-based-routing-bbr",level:3},{value:"Endpoint Picker (EPP)",id:"endpoint-picker-epp",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"goals",children:"Goals"}),"\n",(0,t.jsxs)(n.p,{children:["Our goal is to make KAITO clusters fully compatible with the ",(0,t.jsx)(n.a,{href:"https://docs.google.com/document/d/1hXoSdh9FEs13Yde8DivCYjjXyxa7j4J8erjZPEGWuzc/edit?tab=t.0#heading=h.9j85ih1tpsk",children:"Kubernetes AI Conformance"})," profile, enabling seamless operation within AI-conformant Kubernetes environments. This integration leverages the ",(0,t.jsx)(n.a,{href:"https://gateway-api-inference-extension.sigs.k8s.io/",children:"Gateway API Inference Extension"})," to provide intelligent, inference-aware routing that optimally selects pods for serving each request. The implementation is structured in two phases:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Phase 1: Integrate Gateway API Inference Extension (GWIE) components with KAITO inference workloads to enable inference-aware routing."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Phase 2: (Required > 1 replica of inference pods) Enable and validate prompt-aware and metrics-aware routing using Endpoint Picker (EPP) to select the optimal pod in an ",(0,t.jsx)(n.code,{children:"InferencePool"})," to serve the request."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"non-goals",children:"Non-Goals"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Integrate with a specific Gateway implementation."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"gateway-api-inference-extension-components",children:"Gateway API Inference Extension Components"}),"\n",(0,t.jsx)(n.p,{children:"This section dives into the core components that comprise GWIE. Understanding these individual parts and their interactions is important to understand how GWIE extends the Gateway API to provide inference-specific traffic management and intelligent routing for inference workloads."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Gateway: Must conform to upstream criteria. Currently, kgateway and istio are recommended for GWIE integration."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Extproc: An Envoy filter designed to intercept and modify inference requests by connecting to an external gRPC server. This allows for dynamic examination and alteration of headers, body, and trailers, enabling advanced routing logic like Endpoint Picker (EPP) and Body-Based Routing (BBR) that are implemented as these external gRPC servers."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"InferencePool"}),": A Kubernetes CRD that defines a specialized group of model servers (pods) and the associated endpoint picker (EPP) inference extension responsible for scheduling requests among them. It functions similarly to a standard Kubernetes Service."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"InferenceModel"}),": A Kubernetes CRD that defines a specific model or adapter and its configuration, allowing for granular management of individual model versions or fine-tuning."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Body-Based Routing (BBR): An Extproc implementation that analyzes the HTTP request body to extract the intended model name, which it then adds to a new header (X-Gateway-Model-Name=model-name). This empowers the Gateway's HTTPRoute to make informed routing decisions based on the dynamically injected model name. For more details, refer to this guide."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Endpoint Picker (EPP): Another Extproc implementation responsible for inference pod selection. Once the HTTPRoute has directed a request to an ",(0,t.jsx)(n.code,{children:"InferencePool"})," backend, EPP (as part of the Envoy filter chain) performs the following steps to choose the best pod:"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["It lists all pods selected by the ",(0,t.jsx)(n.code,{children:"InferencePool"}),"'s pod label selector."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It can optionally filter this list."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"It scores each pod based on several criteria, such as longest matching prefix-cache, vLLM queue size, and KV cache size. This is very similar to kube-scheduler where it filters and scores each node when scheduling pending pods. Based on the scores, it picks the pod with the maximum score for the request."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Finally, it adds an ",(0,t.jsx)(n.code,{children:"x-gateway-destination-endpoint: <pod-ip>:<port>"})," header to the request, which Envoy then uses as a hint to route the request to the chosen pod. Note that there is a strict one-to-one relationship between an EPP service and an ",(0,t.jsx)(n.code,{children:"InferencePool"}),". For further implementation details, refer to this proposal."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"integration-points",children:"Integration Points"}),"\n",(0,t.jsx)(n.p,{children:"This section will outline the key areas where KAITO will interact and integrate with the Gateway API Inference Extension and its various components."}),"\n",(0,t.jsx)(n.h3,{id:"crds-installation",children:"CRDs Installation"}),"\n",(0,t.jsxs)(n.p,{children:["For ",(0,t.jsx)(n.code,{children:"InferencePool"})," and ",(0,t.jsx)(n.code,{children:"InferenceModel"})," CRDs, we can use the upstream version from ",(0,t.jsx)(n.a,{href:"https://github.com/kubernetes-sigs/gateway-api-inference-extension/tree/main/config/crd/bases",children:"https://github.com/kubernetes-sigs/gateway-api-inference-extension/tree/main/config/crd/bases"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"For Gateway API CRDs, we have two options:"}),"\n",(0,t.jsxs)(n.p,{children:["Upstream: ",(0,t.jsx)(n.a,{href:"https://github.com/kubernetes-sigs/gateway-api/tree/main/config/crd/standard",children:"https://github.com/kubernetes-sigs/gateway-api/tree/main/config/crd/standard"})]}),"\n",(0,t.jsx)(n.p,{children:"For Gateway API implementation-specific CRDs, users will install them during installation."}),"\n",(0,t.jsxs)(n.p,{children:["For KAITO integration, we will only include ",(0,t.jsx)(n.code,{children:"InferencePool"})," and ",(0,t.jsx)(n.code,{children:"InferenceModel"})," CRDs, as these are the ones KAITO will integrate with."]}),"\n",(0,t.jsx)(n.h3,{id:"gateway",children:"Gateway"}),"\n",(0,t.jsxs)(n.p,{children:["Use upstream-compliant Gateways such as ",(0,t.jsx)(n.code,{children:"Istio"})," and ",(0,t.jsx)(n.code,{children:"kgateway"})," for initial integration."]}),"\n",(0,t.jsx)(n.h3,{id:"inferencepool",children:(0,t.jsx)(n.code,{children:"InferencePool"})}),"\n",(0,t.jsxs)(n.p,{children:["Create one ",(0,t.jsx)(n.code,{children:"InferencePool"})," per KAITO Workspace to encapsulate the set of model servers managed by that Workspace. Consider the following KAITO Workspace:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"apiVersion: kaito.sh/v1beta1\nkind: Workspace\nmetadata:\n  name: workspace-phi-4-mini-instruct\n  namespace: default\nresource:\n  count: 1\n  instanceType: Standard_NC80adis_H100_v5\n  labelSelector:\n    matchLabels:\n      accelerator: nvidia\ninference:\n  preset:\n    name: phi-4-mini-instruct\n"})}),"\n",(0,t.jsxs)(n.p,{children:["KAITO Workspace controller will create an ",(0,t.jsx)(n.code,{children:"InferencePool"})," for this workspace, which will look like this:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"apiVersion: inference.networking.x-k8s.io/v1alpha2\nkind: InferencePool\nmetadata:\n  name: workspace-phi-4-mini-instruct\n  namespace: default\nspec:\n  extensionRef:\n    name: workspace-phi-4-mini-instruct-epp # service is defined in the section below\n  selector:\n    kaito.sh/workspace: workspace-phi-4-mini-instruct\n  targetPortNumber: 5000\n"})}),"\n",(0,t.jsx)(n.h3,{id:"inferencemodel",children:(0,t.jsx)(n.code,{children:"InferenceModel"})}),"\n",(0,t.jsxs)(n.p,{children:["Define one ",(0,t.jsx)(n.code,{children:"InferenceModel"})," for each available model in a KAITO workspace. This includes one for the base model and one for each adapter."]}),"\n",(0,t.jsx)(n.p,{children:"Consider the following KAITO Workspace with one adapter:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'apiVersion: kaito.sh/v1beta1\nkind: Workspace\nmetadata:\n  name: workspace-phi-4-mini-instruct\n  namespace: default\nresource:\n  count: 1\n  instanceType: Standard_NC80adis_H100_v5\n  labelSelector:\n    matchLabels:\n      accelerator: nvidia\ninference:\n  preset:\n    name: phi-4-mini-instruct\n  adapters:\n    - source:\n        name: "phi-4-mini-instruct-adapter"\n        image:  "<YOUR_IMAGE>"\n      strength: "0.2"\n'})}),"\n",(0,t.jsxs)(n.p,{children:["KAITO Workspace controller will create an ",(0,t.jsx)(n.code,{children:"InferenceModel"})," for the base model and each adapter, which will look like this:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"# Base model\napiVersion: inference.networking.x-k8s.io/v1alpha2\nkind: InferenceModel\nmetadata:\n  name: phi-4-mini-instruct\n  namespace: default\nspec:\n  modelName: phi-4-mini-instruct\n  poolRef:\n    name: workspace-phi-4-mini-instruct\n---\n# Adapter model\napiVersion: inference.networking.x-k8s.io/v1alpha2\nkind: InferenceModel\nmetadata:\n  name: phi-4-mini-instruct-adapter\n  namespace: default\nspec:\n  modelName: phi-4-mini-instruct-adapter\n  poolRef:\n    name: workspace-phi-4-mini-instruct\n"})}),"\n",(0,t.jsx)(n.h3,{id:"body-based-routing-bbr",children:"Body-Based Routing (BBR)"}),"\n",(0,t.jsxs)(n.p,{children:["BBR is not a core part of KAITO integration but is recommended for deployment when there are multiple ",(0,t.jsx)(n.code,{children:"InferencePools"})," (for example, one llm-d ",(0,t.jsx)(n.code,{children:"InferencePool"})," and one KAITO Workspace ",(0,t.jsx)(n.code,{children:"InferencePool"}),") under the same gateway. We will provide sample manifests in the new KAITO documentation website for deploying BBR, configuring the gateway to use this extproc, and updating HTTPRoutes to route based on the header set by BBR."]}),"\n",(0,t.jsxs)(n.p,{children:["Below is a sample HTTPRoute for the Gateway that uses X-Gateway-Model-Name header injected by BBR to route to the correct ",(0,t.jsx)(n.code,{children:"InferencePool"})," backend:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"apiVersion: gateway.networking.k8s.io/v1\nkind: HTTPRoute\nmetadata:\n  name: kaito-llm-d-route\nspec:\n  parentRefs:\n  - name: inference-gateway\n  rules:\n  - matches:\n    - headers:\n      - type: Exact\n        name: X-Gateway-Model-Name\n        value: kaito-model\n      path:\n        type: PathPrefix\n        value: /\n    backendRefs:\n    - name: workspace-phi-4-mini-instruct\n      kind: InferencePool\n  - matches:\n    - headers:\n      - type: Exact\n        name: X-Gateway-Model-Name\n        value: llm-d-model\n      path:\n        type: PathPrefix\n        value: /\n    backendRefs:\n    - name: llm-d-inference-pool\n      kind: InferencePool\n"})}),"\n",(0,t.jsx)(n.h3,{id:"endpoint-picker-epp",children:"Endpoint Picker (EPP)"}),"\n",(0,t.jsxs)(n.p,{children:["EPP is a core component of the integration, deployed as a gRPC server within the cluster and configured as an Envoy extproc service. The EPP service is referenced from the ",(0,t.jsx)(n.code,{children:"InferencePool"})," custom resource and in compatible Gateway implementations, incorporated into the Envoy filter chain, enabling inference-aware routing. EPP is responsible for intelligently selecting the optimal pod for each inference request based on real-time performance metrics, ensuring efficient load balancing and resource utilization."]}),"\n",(0,t.jsxs)(n.p,{children:["Using the above ",(0,t.jsx)(n.code,{children:"InferencePool"})," example, the EPP deployment will look like this:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: workspace-phi-4-mini-instruct-epp\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      inferencepool: workspace-phi-4-mini-instruct-epp\n  template:\n    metadata:\n      labels:\n        inferencepool: workspace-phi-4-mini-instruct-epp\n    spec:\n      containers:\n      - args:\n        - -poolName\n        - workspace-phi-4-mini-instruct\n        - -poolNamespace\n        - default\n        - -v\n        - "3"\n        - -grpcPort\n        - "9002"\n        - -grpcHealthPort\n        - "9003"\n        - -metricsPort\n        - "9090"\n        image: us-central1-docker.pkg.dev/k8s-staging-images/gateway-api-inference-extension/epp:main\n        name: epp\n        ports:\n        - containerPort: 9002\n          name: grpc\n          protocol: TCP\n        - containerPort: 9003\n          name: grpc-health\n          protocol: TCP\n        - containerPort: 9090\n          name: metrics\n          protocol: TCP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: workspace-phi-4-mini-instruct-epp # used in InferencePool\n  namespace: default\nspec:\n  ports:\n  - name: grpc-ext-proc\n    port: 9002\n  - name: http-metrics\n    port: 9090\n  selector:\n    inferencepool: workspace-phi-4-mini-instruct-epp\n'})}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(n.p,{children:"The following diagram represents a successful integration:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Inference-Aware Routing Layer Integration",src:i(9852).A+"",width:"935",height:"986"})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},9852:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/gateway-api-inference-extension-92a6a5593231acf1275623267e1f253d.png"}}]);
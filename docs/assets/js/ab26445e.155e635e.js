"use strict";(self.webpackChunkkaito_website=self.webpackChunkkaito_website||[]).push([[9624],{7748:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"aikit","title":"AIKit Integration with KAITO","description":"AIKit provides a streamlined way to package and deploy large language models (LLMs) as container images.","source":"@site/docs/aikit.md","sourceDirName":".","slug":"/aikit","permalink":"/kaito/docs/next/aikit","draft":false,"unlisted":false,"editUrl":"https://github.com/kaito-project/kaito/tree/main/website/docs/aikit.md","tags":[],"version":"current","frontMatter":{},"sidebar":"sidebar","previous":{"title":"Headlamp KAITO","permalink":"/kaito/docs/next/headlamp-kaito"},"next":{"title":"Gateway API Inference Extension","permalink":"/kaito/docs/next/gateway-api-inference-extension"}}');var a=i(4848),o=i(8453);const s={},r="AIKit Integration with KAITO",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Deploying AIKit Models to KAITO",id:"deploying-aikit-models-to-kaito",level:2},{value:"Cluster Setup",id:"cluster-setup",level:3},{value:"KAITO Workspace Configuration",id:"kaito-workspace-configuration",level:3},{value:"Custom Model Creation and Integration",id:"custom-model-creation-and-integration",level:4}];function d(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"aikit-integration-with-kaito",children:"AIKit Integration with KAITO"})}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://github.com/kaito-project/aikit/",children:"AIKit"})," provides a streamlined way to package and deploy large language models (LLMs) as container images."]}),"\n",(0,a.jsx)(t.p,{children:"This document demonstrates how to integrate AIKit-built models with KAITO workspaces for efficient AI model deployment on Kubernetes, including CPU-based inference and custom model creation with a variety of supported formats, such as GGUF, GPTQ, EXL2, and more."}),"\n",(0,a.jsxs)(t.p,{children:["For more detailed information about AIKit, please refer to the ",(0,a.jsx)(t.a,{href:"https://kaito-project.github.io/aikit/docs/",children:"AIKit documentation"}),". For any AIKit-related issues, please open an issue in the ",(0,a.jsx)(t.a,{href:"https://github.com/kaito-project/aikit/issues",children:"AIKit repository"}),"."]}),"\n",(0,a.jsx)(t.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(t.p,{children:"AIKit enables you to:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\ud83d\udce6 ",(0,a.jsx)(t.a,{href:"https://kaito-project.github.io/aikit/docs/create-images",children:"Package AI models"})," as OCI container images with minimal configuration"]}),"\n",(0,a.jsx)(t.li,{children:"\ud83e\udd0f Minimal image size, resulting in less vulnerabilities and smaller attack surface with a custom distroless-based image"}),"\n",(0,a.jsx)(t.li,{children:"\ud83c\udfc3 Run models with a variety of inference backends, such as text or image generation"}),"\n",(0,a.jsxs)(t.li,{children:["\ud83d\udda5\ufe0f Supports ",(0,a.jsx)(t.a,{href:"https://kaito-project.github.io/aikit/docs/create-images#multi-platform-support",children:"AMD64 and ARM64 CPUs"})," and ",(0,a.jsx)(t.a,{href:"https://kaito-project.github.io/aikit/docs/gpu",children:"GPU-accelerated inferencing with NVIDIA GPUs"})]}),"\n",(0,a.jsx)(t.li,{children:"\ud83e\ude84 Integrate seamlessly with KAITO's infrastructure management and deployment workflows"}),"\n"]}),"\n",(0,a.jsx)(t.admonition,{type:"note",children:(0,a.jsx)(t.p,{children:"While AIKit and KAITO integrate well, they are separate projects. AIKit focuses on model packaging and deployment, while KAITO provides infrastructure management and Kubernetes deployment workflows via controllers. There may be differences in what model formats are supported by each project."})}),"\n",(0,a.jsx)(t.h2,{id:"deploying-aikit-models-to-kaito",children:"Deploying AIKit Models to KAITO"}),"\n",(0,a.jsx)(t.h3,{id:"cluster-setup",children:"Cluster Setup"}),"\n",(0,a.jsxs)(t.p,{children:["This guide will provide instructions using a ",(0,a.jsx)(t.a,{href:"https://kind.sigs.k8s.io/",children:"kind"})," cluster for local development and testing so it's easy to get started."]}),"\n",(0,a.jsx)(t.p,{children:"Please note that if you already have a Kubernetes cluster set up, you can skip the cluster setup section."}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:["Download and install ",(0,a.jsx)(t.a,{href:"https://kind.sigs.k8s.io/docs/user/quick-start/",children:"kind"})]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Create a kind cluster:"}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"kind create cluster --name kaito\n"})}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["Install ",(0,a.jsx)(t.a,{href:"/kaito/docs/next/installation#install-kaito-workspace-controller",children:"KAITO workspace controller"})," on your cluster"]}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"kaito-workspace-configuration",children:"KAITO Workspace Configuration"}),"\n",(0,a.jsx)(t.p,{children:"Create a KAITO workspace configuration file to deploy your model. Here's a complete example:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-yaml",metastring:'title="aikit-workspace.yaml"',children:'apiVersion: kaito.sh/v1beta1\nkind: Workspace\nmetadata:\n  name: workspace-llama-3point2-3b\nresource:\n  labelSelector:\n    matchLabels:\n      apps: llama-3point2-3b\n  preferredNodes:\n    - kaito-control-plane\ninference:\n  template:\n    spec:\n      containers:\n        - name: llama-3point2-3b\n          image: ghcr.io/kaito-project/aikit/llama3.2:3b\n          args:\n            - "run"\n            - "--address=:5000"\n'})}),"\n",(0,a.jsxs)(t.admonition,{title:"Memory Requirements",type:"info",children:[(0,a.jsxs)(t.p,{children:["Before deploying models, check the model's memory requirements to avoid Out of Memory (OOM) errors. Add appropriate ",(0,a.jsx)(t.code,{children:"resources.requests.memory"})," and ",(0,a.jsx)(t.code,{children:"resources.limits.memory"})," to your container spec based on the model requirements."]}),(0,a.jsx)(t.p,{children:"For GGUF models:"}),(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"7B models generally require at least 8GB of RAM"}),"\n",(0,a.jsx)(t.li,{children:"13B models generally require at least 16GB of RAM"}),"\n",(0,a.jsx)(t.li,{children:"70B models generally require at least 64GB of RAM"}),"\n"]}),(0,a.jsxs)(t.p,{children:["You can use ",(0,a.jsx)(t.a,{href:"https://github.com/gpustack/gguf-parser-go",children:"gguf-parser-go"})," to get a better estimate for the memory requirements for a given GGUF model, and quantization."]})]}),"\n",(0,a.jsx)(t.p,{children:"Label the nodes with the applicable label to ensure the workspace can schedule pods on them."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"kubectl label nodes kaito-control-plane apps=llama-3point2-3b\n"})}),"\n",(0,a.jsx)(t.p,{children:"Deploy the workspace using:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"kubectl apply -f aikit-workspace.yaml\n"})}),"\n",(0,a.jsxs)(t.p,{children:["AIKit provides a number of pre-built and curated models that can be used directly. Please refer to ",(0,a.jsx)(t.a,{href:"https://kaito-project.github.io/aikit/docs/premade-models",children:"Pre-made Models"})," for available options."]}),"\n",(0,a.jsxs)(t.admonition,{type:"tip",children:[(0,a.jsxs)(t.p,{children:["Alternatively, if you are on a supported cloud provider and want the cloud provider to auto-provision the nodes for you, you can define an ",(0,a.jsx)(t.code,{children:"instanceType"})," for KAITO to autoprovision nodes, including CPU and GPU nodes."]}),(0,a.jsxs)(t.p,{children:["You can specify the instance type based on your cloud provider's offerings. For example, for Azure, you can specify a ",(0,a.jsx)(t.code,{children:"Standard_D2ads_v5"}),", which is a CPU SKU like this:"]}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-yaml",children:'resource:\n  instanceType: "Standard_D2ads_v5"\n  labelSelector:\n    matchLabels:\n      apps: llama-3point2-3b\n'})})]}),"\n",(0,a.jsxs)(t.p,{children:["After workspace deployment succeeds, please refer to ",(0,a.jsx)(t.a,{href:"quick-start#monitor-deployment",children:"Quick Start"})," for monitoring the workspace and testing model inference."]}),"\n",(0,a.jsx)(t.h4,{id:"custom-model-creation-and-integration",children:"Custom Model Creation and Integration"}),"\n",(0,a.jsxs)(t.p,{children:["AIKit provides a simple way to create custom models without additional tools except for ",(0,a.jsx)(t.a,{href:"https://docs.docker.com/desktop/install/linux-install/",children:"Docker"}),"!"]}),"\n",(0,a.jsx)(t.p,{children:"Here's an example on how to create a custom model and integrate it with KAITO:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:'export IMAGE_NAME="your-registry/your-model:latest"\n\ndocker buildx build -t $IMAGE_NAME --push \\\n    --build-arg="model=huggingface://TheBloke/Llama-2-7B-Chat-GGUF/llama-2-7b-chat.Q4_K_M.gguf" \\\n    "https://raw.githubusercontent.com/kaito-project/aikit/main/models/aikitfile.yaml"\n'})}),"\n",(0,a.jsxs)(t.p,{children:["After building the image, you can use it in your KAITO workspace configuration by updating the ",(0,a.jsx)(t.code,{children:"image"})," field."]}),"\n",(0,a.jsxs)(t.p,{children:["For more information on creating custom models, refer to the ",(0,a.jsx)(t.a,{href:"https://kaito-project.github.io/aikit/docs/create-images",children:"AIKit documentation"}),"."]}),"\n",(0,a.jsx)(t.admonition,{type:"info",children:(0,a.jsxs)(t.p,{children:["AIKit supports a subset of backends, (such as ",(0,a.jsx)(t.a,{href:"https://kaito-project.github.io/aikit/docs/llama-cpp",children:(0,a.jsx)(t.code,{children:"llama.cpp"})}),", ",(0,a.jsx)(t.a,{href:"https://kaito-project.github.io/aikit/docs/diffusion",children:(0,a.jsx)(t.code,{children:"diffusers"})}),", ",(0,a.jsx)(t.a,{href:"https://kaito-project.github.io/aikit/docs/exllama2",children:(0,a.jsx)(t.code,{children:"exllamav2"})}),", and others) from ",(0,a.jsx)(t.a,{href:"https://localai.io/",children:"LocalAI"})," at this time. Please see ",(0,a.jsx)(t.a,{href:"https://kaito-project.github.io/aikit/docs/",children:"Inference Supported Backends"})," section for more details, and updates."]})})]})}function h(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,t,i)=>{i.d(t,{R:()=>s,x:()=>r});var n=i(6540);const a={},o=n.createContext(a);function s(e){const t=n.useContext(o);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),n.createElement(o.Provider,{value:t},e.children)}}}]);
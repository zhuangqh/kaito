"use strict";(self.webpackChunkkaito_website=self.webpackChunkkaito_website||[]).push([[418],{9799:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"faq","title":"FAQ","description":"How do I ensure preferred nodes are correctly labeled for use in my workspace?","source":"@site/versioned_docs/version-v0.7.x/faq.md","sourceDirName":".","slug":"/faq","permalink":"/kaito/docs/faq","draft":false,"unlisted":false,"editUrl":"https://github.com/kaito-project/kaito/tree/main/website/versioned_docs/version-v0.7.x/faq.md","tags":[],"version":"v0.7.x","frontMatter":{"title":"FAQ"},"sidebar":"sidebar","previous":{"title":"Usage","permalink":"/kaito/docs/usage"},"next":{"title":"Azure Setup","permalink":"/kaito/docs/azure"}}');var o=t(74848),i=t(28453);const s={title:"FAQ"},a=void 0,l={},d=[{value:"How do I ensure preferred nodes are correctly labeled for use in my workspace?",id:"how-do-i-ensure-preferred-nodes-are-correctly-labeled-for-use-in-my-workspace",level:3},{value:"How to upgrade the existing deployment to use the latest model configuration?",id:"how-to-upgrade-the-existing-deployment-to-use-the-latest-model-configuration",level:3},{value:"How to update model/inference parameters to override the KAITO Preset Configuration?",id:"how-to-update-modelinference-parameters-to-override-the-kaito-preset-configuration",level:3},{value:"What is the difference between instruct and non-instruct models?",id:"what-is-the-difference-between-instruct-and-non-instruct-models",level:3}];function c(e){const n={code:"code",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h3,{id:"how-do-i-ensure-preferred-nodes-are-correctly-labeled-for-use-in-my-workspace",children:"How do I ensure preferred nodes are correctly labeled for use in my workspace?"}),"\n",(0,o.jsx)(n.p,{children:"For using preferred nodes, make sure the node has the label specified in the labelSelector under matchLabels. For example, if your labelSelector is:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"labelSelector:\n  matchLabels:\n    apps: falcon-7b\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Then the node should have the label: ",(0,o.jsx)(n.code,{children:"apps=falcon-7b"}),"."]}),"\n",(0,o.jsx)(n.h3,{id:"how-to-upgrade-the-existing-deployment-to-use-the-latest-model-configuration",children:"How to upgrade the existing deployment to use the latest model configuration?"}),"\n",(0,o.jsxs)(n.p,{children:["When using hosted public models, you can delete the existing inference workload (",(0,o.jsx)(n.code,{children:"Deployment"})," or ",(0,o.jsx)(n.code,{children:"StatefulSet"}),") manually, and the workspace controller will create a new one with the latest preset configuration (e.g., the image version) defined in the current release."]}),"\n",(0,o.jsx)(n.p,{children:"For private models, it is recommended to create a new workspace with a new image version in the Spec."}),"\n",(0,o.jsx)(n.h3,{id:"how-to-update-modelinference-parameters-to-override-the-kaito-preset-configuration",children:"How to update model/inference parameters to override the KAITO Preset Configuration?"}),"\n",(0,o.jsxs)(n.p,{children:["KAITO provides a limited capability to override preset configurations for models that use ",(0,o.jsx)(n.code,{children:"transformer"})," runtime manually."]}),"\n",(0,o.jsxs)(n.p,{children:["To update parameters for a deployed model, perform ",(0,o.jsx)(n.code,{children:"kubectl edit"})," against the workload, which could be either a ",(0,o.jsx)(n.code,{children:"StatefulSet"})," or ",(0,o.jsx)(n.code,{children:"Deployment"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["For example, to enable 4-bit quantization on a ",(0,o.jsx)(n.code,{children:"falcon-7b-instruct"})," deployment:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"kubectl edit deployment workspace-falcon-7b-instruct\n"})}),"\n",(0,o.jsx)(n.p,{children:"Within the deployment specification, locate and modify the command field."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Original:"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all inference_api.py --pipeline text-generation --torch_dtype bfloat16\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Modified to enable 4-bit Quantization:"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all inference_api.py --pipeline text-generation --torch_dtype bfloat16 --load_in_4bit\n"})}),"\n",(0,o.jsx)(n.p,{children:"Currently, we allow users to change the following parameters manually:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"pipeline"}),": For text-generation models this can be either ",(0,o.jsx)(n.code,{children:"text-generation"})," or ",(0,o.jsx)(n.code,{children:"conversational"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"load_in_4bit"})," or ",(0,o.jsx)(n.code,{children:"load_in_8bit"}),": Model quantization resolution."]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Should you need to customize other parameters, kindly file an issue for potential future inclusion."}),"\n",(0,o.jsx)(n.h3,{id:"what-is-the-difference-between-instruct-and-non-instruct-models",children:"What is the difference between instruct and non-instruct models?"}),"\n",(0,o.jsx)(n.p,{children:"The main distinction lies in their intended use cases:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Instruct models"}),": Fine-tuned versions optimized for interactive chat applications. They are typically the preferred choice for most implementations due to their enhanced performance in conversational contexts."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Non-instruct (raw) models"}),": Designed for further fine-tuning with your own data."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>a});var r=t(96540);const o={},i=r.createContext(o);function s(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);
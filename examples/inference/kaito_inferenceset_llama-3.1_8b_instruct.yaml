---
apiVersion: v1
kind: Secret
metadata:
  name: hf-token
type: Opaque
data:
  HF_TOKEN: <base64-encoded-huggingface-token>
---
apiVersion: kaito.sh/v1alpha1
kind: InferenceSet
metadata:
  annotations:
    scaledobject.kaito.sh/auto-provision: "true"
    scaledobject.kaito.sh/metricName: "vllm:num_requests_waiting"
    scaledobject.kaito.sh/threshold: "10"
  name: llama-3-1-8b
spec:
  replicas: 2 # number of workspace CR created by InferenceSet controller
  nodeCountLimit: 10 # optional, total GPU node count limit for InferenceSet
  labelSelector:
    matchLabels:
      # workspace created by InferenceSet controller would use this label in resource.labelSelector
      apps: llama-3-1-8b
  template:
    resource:
      instanceType: "Standard_NC24ads_A100_v4"
    inference: # fields in inference are the same as in workspace.resource.inference
      preset:
        name: llama-3.1-8b-instruct
        presetOptions:
          modelAccessSecret: hf-token
